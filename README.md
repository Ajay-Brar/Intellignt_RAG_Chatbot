# Intellignt_RAG_Chatbot
# ğŸ§  Intelligent Topic-Gated RAG Chatbot

A smart Retrieval-Augmented Generation (RAG) system that uses Machine Learning to classify user intent before retrieving information.
This "Topic-Gating" approach ensures the AI searches only the relevant knowledge base, reducing hallucinations and improving accuracy.

---

## ğŸš€ Features

* **ML-Powered Routing:** A trained Logistic Regression model classifies user queries into topics (e.g., Tech, Biology, Comedy) *before* searching.
* **Targeted RAG:** Maintains separate vector stores for different domains to ensure context retrieval is highly specific.
* **Generative AI:** Uses **Meta Llama 3** (via Groq) to generate human-like, context-aware responses.
* **Open Source Embeddings:** Utilizes HuggingFace's `all-MiniLM-L6-v2` for efficient and free text embeddings.
* **Local Vector Storage:** Uses FAISS (Facebook AI Similarity Search) for fast, local vector storage.

---

## ğŸ› ï¸ Tech Stack

* **Language:** Python 3.10+
* **Orchestration:** LangChain
* **Machine Learning:** Scikit-Learn (TF-IDF Vectorization + Logistic Regression)
* **LLM Provider:** Groq (Llama-3.1-8b-instant)
* **Vector Database:** FAISS
* **Embeddings:** HuggingFace (`sentence-transformers`)

---

## ğŸ“‚ Project Structure

```bash
â”œâ”€â”€ documents/               # Raw knowledge base text files
â”‚   â”œâ”€â”€ tech/                # Python programming docs
â”‚   â”œâ”€â”€ biology/             # Snake biology docs
â”‚   â””â”€â”€ comedy/              # Monty Python docs
â”œâ”€â”€ vector_stores/           # Generated FAISS indexes (created by script)
â”œâ”€â”€ app.py                   # Main application (Run this to chat)
â”œâ”€â”€ train_router.py          # Script to train the ML classifier
â”œâ”€â”€ create_vector_stores.py  # Script to generate vector embeddings
â”œâ”€â”€ queries.csv              # Training data for the ML model
â”œâ”€â”€ requirements.txt         # Python dependencies
â””â”€â”€ .env                     # API keys (Git ignored)
```
How to Run
This system is built in 3 modular steps:

Step 1: Train the Router
Train the Machine Learning model to recognize topics based on the data in queries.csv.

terminal

python train_router.py
Output: Generates router_model.joblib

Step 2: Build the Knowledge Base
Read documents from the documents/ folder and create the FAISS vector stores.

terminal

python create_vector_stores.py
Output: Populates the vector_stores/ directory.

Step 3: Run the Chatbot
Start the CLI application to interact with the AI.

terminal

python app.py
